Проект Sirius Leto 2026 — сервис мониторинга посещаемости с AI-детекцией и распознаванием лиц.

Краткое описание
- Backend: Flask + модули AI в src/backend
- Frontend: простые Jinja2 шаблоны в src/frontend/templates
- Модели: yolov8 (в assets/models), face recognition (DeepFace)

Требования
- Python 3.10+
- Рекомендуется виртуальное окружение
- На Windows: cmd.exe (примеры ниже адаптированы под cmd)

Быстрая установка
1. Клонировать репозиторий (если ещё не клонирован):

```cmd
git clone <репозиторий> sirius_leto_2026
cd sirius_leto_2026
```

2. Создать и активировать виртуальное окружение (Windows cmd):

```cmd
python -m venv venv
venv\Scripts\activate
```

3. Установить зависимости:

```cmd
pip install -r requirements.txt
```

4. (Опционально) Установите дополнительные библиотеки для GPU/ultralytics, если планируете использовать их:

```cmd
pip install ultralytics torch torchvision # при необходимости
```

Конфигурация (переменные окружения)
- Файл .env в корне проекта (не храните секреты в репозитории).
- Минимальные переменные:

```
# пример .env
CAMERA_SOURCE=0
```
- CAMERA_SOURCE — индекс камеры (0,1,...) или путь к видеофайлу. По умолчанию 0.

Модели
- По умолчанию проект ожидает модели в папке `src/backend/assets/models` или `src/backend/assets`:
  - `yolov8n.pt` (детектор/трекер)
  - `yolov8n-pose.pt` (pose model) — если используете ONNX для pose, укажите соответствующий путь.
- Если используете `.pt` и ultralytics, убедитесь, что библиотека ultralytics установлена.

Запуск приложения
```cmd
python src/main.py
```
- По умолчанию доступно на `http://0.0.0.0:5000`.
- Главная страница: `/` (только на ней отображается видеопоток).
- Видеопоток (MJPEG): `/video_feed`
- Страница групп: `/groups`
- Страница регистрации: `/register`

Что делать если камера не работает
- В Windows с OpenCV иногда появляются предупреждения MSMF и `can't grab frame`. В таком случае сервис переключится на fallback: будет показывать первое изображение из `src/backend/assets/images`.
- Чтобы явно указать видео-файл как источник, в `.env` укажите путь: `CAMERA_SOURCE=D:\path\to\video.mp4`.

Работа с распознаванием лиц
- Фото студентов хранятся в `src/backend/assets/images`.
- При регистрации через форму (`/register`) фото сохраняется и DeepFace использует кеш представлений (`representations_facenet.pkl`), который можно удалить для перегенерации.

Отладка и логи
- Основные сообщения и ошибки выводятся в терминал, где запущен Flask (print / traceback). Ищите строки вида:
  - `[Container] person_detector initialized` — детектор загружен
  - `[Track] frame N - tracked_people: X` — сколько людей обнаружено
  - `[Track] recognition filename: ...` — результат распознавания лица
  - `[Monitor] tracking error: ...` — ошибки трекинга/инференса

Частые проблемы и решения
- "The truth value of an array is ambiguous" — исправлено в коде; если возникает снова — вероятно старая версия пакета. Убедитесь, что вы запускаете обновлённый код из репозитория.
- DeepFace/TensorFlow выводит предупреждения — они информативны и обычно не блокируют работу.
- Если модели не загружены (ultralytics/torch отсутствуют), отключите использование GPU или установите требуемые пакеты.

Разработка и тестирование
- Для локального теста можно положить несколько изображений в `src/backend/assets/images` — сервис использует их как fallback, если камера недоступна.
- Для быстрого теста инференса: запустите `python src/main.py` и откройте `/`.

Кнопки быстрого запуска (cmd.exe)
```cmd
# создать виртуальное окружение
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
python src/main.py
```

Контакты и дальнейшие шаги
- Если нужно, могу добавить CI/test-скрипт для автоматической проверки зависимостей и запуска smoke-test (сохранение одного кадра с аннотациями).

---
Файл README даёт минимальную и понятную инструкцию для развёртывания и первых шагов с проектом.

